# HPC_Jacobi-Methodd
This repository contains the implementation of the **Jacobi Method for the iterative solution of Poisson's Equation in one dimension (1D)**. It utilizes High-Performance Computing (HPC) techniques to efficiently solve this equation, providing a numerical solution for problems in fields such as physics, engineering, and applied sciences. It provides three distinct implementations: **sequential, threaded (using pthreads), and process-based (using fork)**, each with its specific characteristics and optimizations.

# Prerequisites

Before proceeding with the optimization analysis, ensure the following prerequisites are met:
* **Linux Environment:** The optimization analysis is conducted on a Linux-based operating system. Make sure you have access to a Linux environment to compile and run the code.
* **GCC Compiler:**  Ensure that the GCC compiler is installed on your system. You can install GCC on Linux using package managers like `apt` (for Debian-based distributions) or `yum` (for Red Hat-based distributions). 

   **For Debian-based distributions:**
  
       sudo apt update
       sudo apt install gcc

    **For Red Hat-based distributions:**
  
       sudo yum install gcc

## 1. Sequential Implementation: 
The code is written in C and includes a sequential implementation of the algorithm along with a bash script for executing performance tests. This implementation is stored in the **SecuencialJabobi** folder. Also, we explore the impact of different optimization levels (-O1, -O2, -O3). The compiled executables and their corresponding performance results of optimization are stored in the **"Optimization_CPU** folder.

### Optimization levels
  **-O1:** Basic optimization level, focusing on improving compilation time and code size without sacrificing runtime performance significantly.
  
  **-O2:** Medium optimization level, including additional optimizations such as loop unrolling and function inlining to improve runtime performance further.
  
  **-O3:** Highest optimization level, enabling aggressive optimizations such as vectorization and loop restructuring to maximize runtime performance, potentially at the cost of increased compilation time.

### Code overview
The Jacobi iterative method is used to solve Poisson’s equation in one dimension. It iteratively updates the solution until convergence is achieved. The provided implementation includes a **function to perform the Jacobi iterations** and another **function to write the solution to a file**. Additionally, a **bash script** is included to run performance tests on the sequential implementation. It records the execution time for each test run in a **csv file**.

### Files
  * **jacobiSecuencial.c:** Contains the implementation of the Jacobi iterative algorithm along with the main function for running the solver.
  * **jacobiSecuencial.sh:** Bash script to execute performance tests on the sequential implementation.
  * **resultadoJacobiSecuencial.csv:** Output file generated by the script to store performance results.

### Usage
  **Compilation and optimization:** 
  
  * _Command to compile the code without optimization:_
    
        gcc -g jacobiSecuencial.c -o jacobiSecuencialExe
    
            
  * _Commands used to compile the code with each optimization level using the GCC comppiler:_
  
        gcc -O1 jacobiSecuencial.c -o jacobiSecuencialExe
        gcc -O2 jacobiSecuencial.c -o jacobiSecuencialExe
        gcc -O3 jacobiSecuencial.c -o jacobiSecuencialExe
        
  **Running the performance tests:** 
   
       ./jacobiSecuencialScript.sh

### Performance analysis
Pros:
  * Straightforward implementation. 
  * Suitable for small array sizes or systems where parallelism is not feasible.
    
Cons:
   * Limited scalability for large datasets.
   * Execution time increases linearly with the number of iterations.

### Performance results
The CSV files contain execution times for different array sizes, providing insights into the impact of optimization on the solver's performance. These results can be analyzed to understand the execution time trends and scalability of the algorithm.

## 2. Multi-threading implementation
The code is written in C and includes a multi-threaded implementation of the algorithm along with a bash script for executing performance tests. The solver is parallelized using POSIX threads (pthread library) to leverage multi-core processors for faster computation. This implementation is stored in the **HilosJabobi** folder.

### Thread configuration
**Thread Count:** The number of threads can be specified at runtime. The program will divide the workload evenly among the specified number of threads, with each thread processing its segment of the data array. 

### Code overview
The main components include a thread function for parallel computation, a coordinator function to manage threads, and a utility function to output the solution. A bash script is provided to automate execution and performance testing, capturing runtime data for various configurations in a csv file.

### Files
  * **jacobiHilos.c:** The main C file with the Jacobi solver's multithreaded implementation.
  * **jacobiHilosScript.sh:** Bash script for automating performance tests across different thread counts and problem sizes.
  * **resultadoJacobiHilos.csv:** Generated by the script, this file logs the performance metrics for analysis.
    
### Usage

**Compilation:**
Command to compile the code (ensure pthreads library is linked):

    gcc -o jacobiHilosExe jacobiHilos.c -pthread

Running the performance tests:

    ./jacobiHilos.sh

### Performance insights

**Pros:**
* Significant performance uplift on multicore systems by leveraging parallelism.
* Scalability with the number of threads, albeit with a practical upper limit dictated by the hardware capabilities.

**Cons:**
* The overhead associated with thread management and synchronization may offset the performance gains, particularly for smaller problem sizes or excessively high thread counts.
* Achieving optimal performance is contingent upon a balanced interplay between the problem size and the available number of processor cores.

## 3. Process-Based Implementation
The provided code is implemented in C and utilizes a multi-process approach to parallelize the execution of the Jacobi method for solving partial differential equations. Alongside the C program, there is a Bash script designed to facilitate performance testing across various problem sizes and process counts. This parallelization strategy employs the `fork()` system call to create multiple processes, enabling the utilization of multi-core processors to enhance computational efficiency. Each process operates on a segment of the problem space, contributing to a faster overall solution by working concurrently. This implementation is stored in the **ProcesosJabobi** folder.

### Process configuration

**Process Count:** The number of processes can be dynamically set at runtime. The workload is evenly distributed among the specified processes, with each one handling a dedicated portion of the data array.

### Code overview
The key components of this implementation include a subroutine for each process to perform its segment of the computation, a main function that orchestrates the processes, and a utility function for writing the computed solution to a file. Additionally, a Bash script is provided to automate the execution of the solver under different configurations and to log the runtime metrics in a CSV file for further analysis.

### Files
* **jacobiProcesos.c:** The primary C file containing the process-based parallel implementation of the Jacobi solver.
* **jacobiProcesosScript.sh:** Bash script designed to automate performance testing, varying the problem sizes and process counts.
* **resultadoJacobiProcesos.csv:** This file is generated by the script and records the performance metrics for subsequent analysis.

### Usage

**Compilation:**

To compile the code, use the following command:

    gcc -g jacobiProcesos.c -o jacobiProcesosExe

Running the performance tests:

    ./jacobiProcesosScript.sh

### Performance insights
**Pros:**
* Offers a substantial performance boost on systems with multiple cores by exploiting parallel execution.
* The performance scales with the number of processes, allowing for efficient utilization of available computational resources.

**Cons:**
* Process creation and management overhead might diminish the performance benefits, particularly for smaller problem sizes or an excessive number of processes.
* Optimal performance is dependent on finding the right balance between the problem size and the number of processes, taking into account the hardware constraints and the overhead of inter-process communication.


# More about Jacobi Method
For a comprehensive understanding of the Jacobi Iterative Solution of Poisson’s Equation in 1D, please refer to the attached document:

[https://people.sc.fsu.edu/~jburkardt/presentations/jacobi_poisson_1d.pdf] - This document provides a detailed exploration of the Jacobi method, including its mathematical foundation, convergence criteria, and practical applications.


    
